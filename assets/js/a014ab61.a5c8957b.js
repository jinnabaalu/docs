"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4729],{8071:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"elasticsearch/RunLogstashPipeineWithContainer","title":"\ud83d\udc33 Basic Logstash Pipeline","description":"We\'ll use Logstash as an ETL engine to move data from PostgreSQL into Elasticsearch. Fast, clean, and production-ready.","source":"@site/docs/elasticsearch/RunLogstashPipeineWithContainer.md","sourceDirName":"elasticsearch","slug":"/ElasticStack/BasicLogstashPipeline","permalink":"/oio/docs/ElasticStack/BasicLogstashPipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/elasticsearch/RunLogstashPipeineWithContainer.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"slug":"/ElasticStack/BasicLogstashPipeline"},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\udc33 Run Kibana Docker Container","permalink":"/oio/docs/ElasticStack/KibanaDockerContainer"},"next":{"title":"\ud83d\udc33 Enable XPack in Elasticsearch Container","permalink":"/oio/docs/ElasticStack/EnableXPackInElasticsearchContainer"}}');var r=t(4848),a=t(8453);const i={sidebar_position:5,slug:"/ElasticStack/BasicLogstashPipeline"},o="\ud83d\udc33 Basic Logstash Pipeline",c={},l=[{value:"\ud83d\udee0\ufe0f Prerequisites",id:"\ufe0f-prerequisites",level:3},{value:"\ud83d\udcc1 Folder Structure",id:"-folder-structure",level:3},{value:"Pipeline Structure",id:"pipeline-structure",level:3},{value:"<strong>3. Output</strong>: Where the data is sent (e.g., Elasticsearch, S3, Kafka).",id:"3-output-where-the-data-is-sent-eg-elasticsearch-s3-kafka",level:2},{value:"Create folders and files",id:"create-folders-and-files",level:3},{value:"\ud83d\udc33 Run logstash container",id:"-run-logstash-container",level:2}];function d(e){const s={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(s.header,{children:(0,r.jsx)(s.h1,{id:"-basic-logstash-pipeline",children:"\ud83d\udc33 Basic Logstash Pipeline"})}),"\n",(0,r.jsxs)(s.p,{children:["We'll use Logstash as an ETL engine to move data from ",(0,r.jsx)(s.strong,{children:"PostgreSQL into Elasticsearch"}),". Fast, clean, and production-ready."]}),"\n",(0,r.jsx)(s.h3,{id:"\ufe0f-prerequisites",children:"\ud83d\udee0\ufe0f Prerequisites"}),"\n",(0,r.jsxs)(s.p,{children:["Run Elasticsearch, in this case for testing you can folowing ",(0,r.jsx)(s.a,{href:"/oio/docs/ElasticStack/ElasticsearchSingleNodeDockerContainer",children:"Single Node Cluster Setup"})]}),"\n",(0,r.jsx)(s.h3,{id:"-folder-structure",children:"\ud83d\udcc1 Folder Structure"}),"\n",(0,r.jsx)(s.p,{children:"We'll create or download the necessary files and organize them following the structure below."}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"cd logstash\n.\n\u251c\u2500\u2500 jdbc-drivers\n\u2502\xa0\xa0 \u2514\u2500\u2500 postgresql-42.7.5.jar\n\u251c\u2500\u2500 pipeline\n\u2502\xa0\xa0 \u251c\u2500\u2500 pg-table-es.conf\n\u251c\u2500\u2500 postgres\n\u2502\xa0\xa0 \u251c\u2500\u2500 docker-compose.yml\n\u2502\xa0\xa0 \u251c\u2500\u2500 init.sql\n\u2514\u2500\u2500 docker-compose.yml\n"})}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h3,{id:"pipeline-structure",children:"Pipeline Structure"}),"\n",(0,r.jsx)(s.p,{children:"Pipelines should be well-configured, organized, and prioritized for smooth data flow. Treat your pipelines like first-class citizens. A Logstash pipeline has 3 blocks"}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"1. Input"}),": Where the data comes from (e.g., JDBC, Beats, HTTP, etc.)."]}),"\n",(0,r.jsxs)(s.p,{children:[(0,r.jsx)(s.strong,{children:"2. Filter"}),": (Optional) Used to parse, transform, and clean data."]}),"\n",(0,r.jsxs)(s.h2,{id:"3-output-where-the-data-is-sent-eg-elasticsearch-s3-kafka",children:[(0,r.jsx)(s.strong,{children:"3. Output"}),": Where the data is sent (e.g., Elasticsearch, S3, Kafka)."]}),"\n",(0,r.jsx)(s.h3,{id:"create-folders-and-files",children:"Create folders and files"}),"\n",(0,r.jsx)(s.p,{children:"Create folder structure"}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"cd logstash/\nmkdir -p jdbc-drivers pipeline postgres\n"})}),"\n",(0,r.jsxs)(s.p,{children:["Download PostgreSQL JDBC Driver, for latest version check ",(0,r.jsx)(s.a,{href:"https://jdbc.postgresql.org/download/",children:"here"})]}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"wget -P jdbc-drivers/ https://jdbc.postgresql.org/download/postgresql-42.7.5.jar\n"})}),"\n",(0,r.jsx)(s.p,{children:"Download Logstash Docker Compose and Pipeline Config"}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"wget -O docker-compose.yml https://raw.githubusercontent.com/jinnabaalu/ELKOperations/refs/heads/main/logstash/postgres-to-elasticsearch/docker-compose.yml\nwget -P pipeline/ https://raw.githubusercontent.com/jinnabaalu/ELKOperations/refs/heads/main/logstash/postgres-to-elasticsearch/pipeline/pg-table-es.conf\n"})}),"\n",(0,r.jsx)(s.p,{children:"Download PostgreSQL Dcoker Container Setup Files"}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"wget -P postgres/ https://raw.githubusercontent.com/jinnabaalu/ELKOperations/refs/heads/main/logstash/postgres-to-elasticsearch/postgres/docker-compose.yml\nwget -P postgres/ https://raw.githubusercontent.com/jinnabaalu/ELKOperations/refs/heads/main/logstash/postgres-to-elasticsearch/postgres/init.sql\n\n# View the content of init.sql to know the data getting inserted\ncd postgres/\ndocker-compose up -d\n"})}),"\n",(0,r.jsxs)(s.blockquote,{children:["\n",(0,r.jsxs)(s.p,{children:["Based on the given ",(0,r.jsx)(s.code,{children:"init.sql"})," data, it will create the databse and tables. You can check what you have inserted into the postgres. I have ",(0,r.jsx)(s.code,{children:"vbvdb"})," database, and ",(0,r.jsx)(s.code,{children:"employe"})]}),"\n"]}),"\n",(0,r.jsx)(s.hr,{}),"\n",(0,r.jsx)(s.h2,{id:"-run-logstash-container",children:"\ud83d\udc33 Run logstash container"}),"\n",(0,r.jsx)(s.p,{children:"Understand the pipeline:"}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:'cat pipeline/pg-table-es.conf \n\ninput {\n  jdbc {\n    jdbc_connection_string => "jdbc:postgresql://postgres:5432/vbvdb" # Postgres connection string\n    jdbc_user => "vbv" # postgres user\n    jdbc_password => "vbv" # postgres user password\n    jdbc_driver_class => "org.postgresql.Driver" # JDBC driver class to connect to the postgres\n    jdbc_driver_library => "/usr/share/logstash/jdbc-drivers/postgresql-42.7.5.jar" # jar used for supporting the Class defined\n    statement => "SELECT * from employees" # select the data from table \n    schedule => "* * * * *" # Runs every 1min. \n  }\n}\noutput {\n  elasticsearch {\n    hosts => ["http://elasticsearch:9200"] # Elasticsearch connection\n    index => "employees" # Creates the index\n    document_id => "%{id}" # Like column in postgres, every record is called document in elasticsearch, which is the id of the docuemnt. \n  }\n}\n'})}),"\n",(0,r.jsx)(s.p,{children:"Run the logstash container now"}),"\n",(0,r.jsx)(s.pre,{children:(0,r.jsx)(s.code,{className:"language-bash",children:"docker-compose up -d\n"})}),"\n",(0,r.jsxs)(s.ul,{children:["\n",(0,r.jsxs)(s.li,{children:["Check if Logstash container is up and healthy, ",(0,r.jsx)(s.code,{children:"docker ps -a"}),", Look for the container named logstash \u2014 Status should be healthy or Up."]}),"\n",(0,r.jsxs)(s.li,{children:["Tail the container logs and check if the SELECT query runs, ",(0,r.jsx)(s.code,{children:'docker logs logstash | grep "SELECT"'})," If you see your SELECT * FROM employees query firing, the pipeline is alive and pulling data \ud83d\udd25."]}),"\n",(0,r.jsxs)(s.li,{children:["Check if Elasticsearch actually got the data, ",(0,r.jsx)(s.code,{children:"curl -s http://localhost:9200/_cat/indices?v"}),", Look for an index called employees."]}),"\n",(0,r.jsxs)(s.li,{children:["Count the documents inside employees index, ",(0,r.jsx)(s.code,{children:"curl -s http://localhost:9200/employees/_count?pretty"})]}),"\n",(0,r.jsx)(s.li,{children:"Question for you \ud83e\udef5.  What is pretty in the above query, try with  pretty and try without pretty?"}),"\n",(0,r.jsxs)(s.li,{children:["Try another query, to search data in index ",(0,r.jsx)(s.code,{children:"curl -s http://localhost:9200/employees/_search?pretty"})]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,r.jsx)(s,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,s,t)=>{t.d(s,{R:()=>i,x:()=>o});var n=t(6540);const r={},a=n.createContext(r);function i(e){const s=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),n.createElement(a.Provider,{value:s},e.children)}}}]);